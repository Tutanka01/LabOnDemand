# LabOnDemand ‚ú®

<div align="center">
    <h2 align="center"><a href="https://makhal.fr"><img alt="pangolin" src="Diagrammes/Images/banner-projet.jpeg" width="400" /></a></h2>
</div>

**LabOnDemand** est une plateforme open-source de gestion de laboratoires virtuels, con√ßue pour permettre aux √©tudiants et professeurs de cr√©er et g√©rer facilement des environnements de travail isol√©s sur Kubernetes. D√©ployez des instances VS Code, Jupyter Notebooks, ou vos propres applications conteneuris√©es en quelques clics !

[![License: AGPL v3](https://img.shields.io/badge/License-AGPL%20v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
<!-- Ajoutez d'autres badges ici (build status, etc.) quand ils seront pertinents -->

## üìπ Pr√©sentation du Projet

Regardez notre vid√©o de pr√©sentation qui explique les principales fonctionnalit√©s et l'utilisation de LabOnDemand :

[![LabOnDemand Video](https://img.shields.io/badge/Vid√©o-Pr√©sentation%20du%20Projet-red)](Diagrammes/Video/LabOnDemand.mp4)

## üöÄ Fonctionnalit√©s Cl√©s

*   D√©ploiement Facile : UI pour lancer des environnements pr√©-configur√©s (VS Code, Jupyter, WordPress) ou des images Docker personnalis√©es.
*   Gestion Kubernetes Simplifi√©e : cr√©ation de Deployments/Services, labels standardis√©s, et conformit√© K8s (validation des noms).
*   R√¥les & Autorisations : √©tudiants, enseignants, admins. Les √©tudiants peuvent supprimer uniquement leurs propres applications (contr√¥le d‚Äô√©tiquettes managed-by=labondemand, user-id).
*   Quotas par R√¥le (enforcement c√¥t√© serveur) : limites sur nombre d‚Äôapps, CPU et m√©moire avec mode fail-closed si la mesure est indisponible. Carte de quotas sur le dashboard.
*   Observabilit√© par Application : m√©triques CPU (m) et m√©moire (Mi) par application, en Live (metrics-server) ou estimation (requests). Liste triable par consommation.
*   Statistiques Admin : vue d√©di√©e pour l‚Äô√©tat cluster/noeuds (si metrics-server pr√©sent), avec agr√©gations utiles.
*   WordPress pour √âtudiants : stack compl√®te WordPress + MariaDB g√©r√©e; suppression traite la stack (web + db) proprement.
*   S√©curit√© des Sessions : cookies HttpOnly, Secure, SameSite, domaine/expiration configurables; contr√¥les de r√¥le c√¥t√© API.
*   Sessions distribu√©es via Redis : stockage des sessions dans Redis externe pour scalabilit√© et HA (plus de SPOF en m√©moire).
*   Acc√®s Simplifi√© : exposition via NodePort (par d√©faut), configurable.
*   Templates Dynamiques : templates en base (ic√¥ne/desc/tags) + runtime-configs pour piloter l‚Äôaffichage aux √©tudiants.
*   Terminal Web int√©gr√© (sans SSH) : terminal in-browser vers un pod, avec Xterm.js (fit/attach/webgl), resize dynamique, keepalive, faible latence. Acc√®s DB pods restreint pour les √©tudiants.
*   Stack LAMP cl√© en main : Apache+PHP, MySQL, phpMyAdmin avec plusieurs URLs dans les d√©tails de d√©ploiement; index.php par d√©faut styl√© UPPA; web non-root et capacit√©s minimales.
*   Persistance ¬´ best-effort ¬ª : montages PVC pour VS Code, Jupyter et le web LAMP (fallback en emptyDir si StorageClass indisponible). MariaDB/WordPress DB en PVC 1Gi par d√©faut.

Voir aussi:
- Documentation LAMP: documentation/lamp.md
- Terminal web: documentation/terminal.md
- WordPress: documentation/wordpress.md

## Quotas pour les √©tudiants (valeurs et justification)

Pour garantir une exp√©rience fluide pour tous et √©viter la saturation du cluster par un seul utilisateur, des quotas sp√©cifiques s‚Äôappliquent aux comptes ¬´ √©tudiant ¬ª.

- Applications (logiques): 4 max ‚Äî une stack WordPress (web + DB) compte pour 1 application.
- Pods: 6 max ‚Äî permet 2 apps mono-pod + 1 stack WordPress (2 pods) avec une marge.
- Somme des requests CPU: 2500m par namespace √©tudiant.
- Somme des requests m√©moire: 6Gi par namespace √©tudiant.
- Objets K8s: jusqu‚Äô√† 8 Deployments et 10 Services.
- Stockage: jusqu‚Äô√† 2 PVC et 2Gi de requests.storage.
- Plafonds par conteneur (c√¥t√© API/LimitRange):
    - CPU: request ‚â§ 500m, limit ‚â§ 1000m
    - M√©moire: request ‚â§ 512Mi, limit ‚â§ 1Gi
    - R√©plicas: ‚â§ 1 par application √©tudiante

Pourquoi ces limites ? Exemple concret:

- Cas d‚Äôusage vis√©: un √©tudiant lance 2 environnements VS Code + 1 WordPress (web + DB).
- Ressources typiques par pod (defaults/maximums √©tudiants): 500m CPU, 512Mi m√©moire.
- Consommation totale: 4 pods √ó (500m, 512Mi) = 2000m CPU et ~2Gi m√©moire ‚Äî bien sous les plafonds (2500m, 6Gi), laissant:
    - ~500m CPU pour respirer (pics, t√¢ches syst√®me)
    - ~4Gi de m√©moire de marge (√©vite l‚ÄôOOM et conserve de la capacit√© cluster)

Ce dimensionnement:

- offre une vraie autonomie (plusieurs ateliers en parall√®le),
- reste align√© avec les bonnes pratiques Kubernetes (requests r√©alistes, limits raisonnables),
- prot√®ge l‚Äôinfrastructure partag√©e des abus involontaires.

O√π c‚Äôest impl√©ment√© dans le code:

- `backend/k8s_utils.py`
    - `get_role_limits('student')` ‚Üí max_apps=4, max_requests_cpu_m=2500, max_requests_mem_mi=6144, max_pods=6
    - `ensure_namespace_baseline()` ‚Üí ResourceQuota (pods, requests.cpu=2500m, requests.memory=6Gi, limits.cpu=5, limits.memory=8Gi, counts Deployments/Services, PVC/requests.storage) et LimitRange (defaults/requests)
    - `clamp_resources_for_role('student', ...)` ‚Üí plafonds par conteneur et r√©plicas
- `backend/deployment_service.py`
    - `_assert_user_quota()` et pr√©validation K8s ‚Üí refus explicite si d√©passement
    - `get_user_quota_summary()` ‚Üí donn√©es pour la carte ¬´ Vos ressources ¬ª
- UI: carte Quotas sur le dashboard (`frontend/index.html`, `frontend/script.js`) aliment√©e par `GET /api/v1/quotas/me`.


## ÔøΩüèóÔ∏è Architecture du Projet

LabOnDemand est structur√© autour de trois composants principaux :

1.  **Backend API (FastAPI/Python)** : Le cerveau de l'application. Il g√®re la logique m√©tier, les interactions avec l'API Kubernetes et expose les endpoints pour le frontend.
2.  **Frontend (HTML/JavaScript/CSS)** : L'interface utilisateur web, permettant aux utilisateurs d'interagir avec l'API pour g√©rer leurs laboratoires.
3.  **Base de Donn√©es (MariaDB)** : Utilis√©e pour stocker les informations relatives aux laboratoires, utilisateurs (fonctionnalit√© future), et configurations.
4.  **Proxy NGINX** : Sert le frontend statique et redirige les appels API vers le backend FastAPI.

##  visionary Architecture (Objectif √† Terme)

L'objectif est de faire √©voluer LabOnDemand vers une solution robuste et hautement disponible :

```mermaid
graph TD
    %% --- Style Definitions ---
    classDef default fill:#ececff,stroke:#9370db,stroke-width:2px,color:#333;
    classDef external fill:#fceecb,stroke:#e9a70f,stroke-width:2px,color:#333;
    classDef network fill:#d1e7dd,stroke:#146c43,stroke-width:2px,color:#333;
    classDef haproxy fill:#f8d7da,stroke:#842029,stroke-width:2px,color:#333;
    classDef k8snode fill:#cfe2ff,stroke:#0a58ca,stroke-width:2px,color:#333;
    classDef k8singress fill:#fff3cd,stroke:#997404,stroke-width:1px,color:#333;
    classDef k8sapp fill:#d1e7dd,stroke:#0f5132,stroke-width:1px,color:#333;
    classDef k8ssvc fill:#e2d9f3,stroke:#563d7c,stroke-width:1px,color:#333;

    %% --- External Layer ---
    User["Utilisateur"]:::external
    DNS["DNS<br/>(*.lab.makhal.fr)"]:::external
    User -- "DNS Lookup" --> DNS

    %% --- HA Layer with Keepalived ---
    subgraph "HAProxy + Keepalived Layer"
        direction TB
        VIP["<b>Adresse IP Virtuelle (VIP)</b><br/>(G√©r√©e par Keepalived)"]:::network

        subgraph "HAProxy Instances"
            direction LR
            HAProxy1["<b>HAProxy 1 (MASTER)</b><br/>Actif - D√©tient la VIP<br/><i>Keepalived</i>"]:::haproxy
            HAProxy2["<b>HAProxy 2 (BACKUP)</b><br/>Passif - Pr√™t √† prendre le relais<br/><i>Keepalived</i>"]:::haproxy
        end
        HAProxy1 <-- "VRRP Heartbeat" --> HAProxy2
    end

    DNS -- "Virtual IP" --> VIP
    User -- "Connects (HTTP/S)" --> VIP
    VIP -- "Traffic to Active" --> HAProxy1

    %% --- Kubernetes Cluster Layer ---
    subgraph "Kubernetes Cluster (3 Nodes)"
        direction TB
        subgraph "Worker Nodes"
             direction LR
             Node1["K8s Node 1<br/>(Worker)"]:::k8snode
             Node2["K8s Node 2<br/>(Worker)"]:::k8snode
             Node3["K8s Node 3<br/>(Worker)"]:::k8snode
        end
        IngressSvc["Ingress Controller Service<br/>(Type: NodePort)"]:::k8ssvc
        subgraph "Ingress Controller Pods"
            direction LR
             IngressPod1["Ingress Pod 1"]:::k8singress
             IngressPod2["Ingress Pod 2"]:::k8singress
        end
        AppSvc["Application Service<br/>(Type: ClusterIP)"]:::k8ssvc
        subgraph "Application Pods (ex: VSCode)"
            direction LR
             AppPod1["App Pod 1"]:::k8sapp
             AppPod2["App Pod 2"]:::k8sapp
        end
        HAProxy1 -- "Forward to NodePort" --> Node1
        HAProxy1 -- "Forward to NodePort" --> Node2
        HAProxy1 -- "Forward to NodePort" --> Node3
        Node1 -- "Kube-proxy routes" --> IngressSvc
        Node2 -- "Kube-proxy routes" --> IngressSvc
        Node3 -- "Kube-proxy routes" --> IngressSvc
        IngressSvc -- "Selects Ingress Pod" --> IngressPod1
        IngressSvc -- "Selects Ingress Pod" --> IngressPod2
        IngressPod1 -- "Routes by Rule" --> AppSvc
        IngressPod2 -- "Routes by Rule" --> AppSvc
        AppSvc -- "Selects App Pod" --> AppPod1
        AppSvc -- "Selects App Pod" --> AppPod2
    end
```

## üõ†Ô∏è Mise en Place (D√©veloppement Local)

### Pr√©requis

*   **Docker & Docker Compose :** Pour construire et lancer les services localement.
*   **Cluster Kubernetes Fonctionnel :** Minikube, Kind, K3s, ou un cluster distant.
*   **`kubectl` :** Configur√© pour interagir avec votre cluster.
*   **Helm (Optionnel, mais recommand√©) :** Pour l'installation de l'Ingress Controller.
*   **Fichier `kubeconfig` :** Un fichier `kubeconfig` valide pour l'acc√®s √† votre cluster Kubernetes.

Conseil stockage (dev): pour b√©n√©ficier de la persistance best-effort (PVC), assurez-vous qu‚Äôune StorageClass par d√©faut est disponible (ex. local-path sur k3s). Sinon, les apps d√©marrent en m√©moire (emptyDir) et les donn√©es ne survivent pas aux red√©marrages.

### Configuration Initiale

1.  **Clonez le d√©p√¥t :**
    ```bash
    git clone <URL_DU_DEPOT_LABONDEMAND>
    cd LabOnDemand
    ```

2.  **Configuration Kubernetes :**
    *   **‚ö†Ô∏è Configuration et Acc√®s au Cluster :** L'application n√©cessite l'acc√®s √† un cluster Kubernetes via un fichier `kubeconfig`.
        *   **Pour le d√©veloppement local avec Docker Compose :**
            Le fichier `kubeconfig.yaml` est mont√© comme un volume en lecture seule dans le conteneur API via `compose.yaml` :
            ```yaml
            # Dans compose.yaml, pour le service 'api':
            volumes:
              - ./backend:/app/backend
              - ./.env:/app/.env
              - ./kubeconfig.yaml:/root/.kube/config:ro # Montez votre kubeconfig local en lecture seule
            ```
            Assurez-vous que votre fichier `kubeconfig.yaml` est valide et situ√© √† la racine du projet.
        *   **Pour un d√©ploiement en cluster (Production) :** L'API devrait utiliser un **ServiceAccount Kubernetes** avec les permissions RBAC appropri√©es. Ne jamais embarquer un `kubeconfig` avec des droits √©tendus dans une image.
        *   **Besoin d'aide pour cr√©er un cluster Kubernetes ?** Consultez notre tutoriel sur [Comment installer un cluster Kubernetes](https://makhal.fr/posts/k8s/k8s1-3/) qui vous guidera √† travers le processus d'installation.

3.  **Fichier d'Environnement :**
    Cr√©ez un fichier `.env` √† la racine du projet √† partir de l'exemple (s'il n'y a pas de `.env.example`, cr√©ez-le) :
    ```bash
    cp .env.example .env # Ou cr√©ez .env manuellement
    ```
    Modifiez `.env` avec vos configurations (ports, identifiants de base de donn√©es) :
    ```dotenv
    # Exemple de .env
    API_PORT=8000
    FRONTEND_PORT=80
    DB_PORT=3306
    DB_ROOT_PASSWORD=supersecretrootpassword
    DB_USER=labondemand
    DB_PASSWORD=labondemandpassword
    DB_NAME=labondemand
    # DEBUG_MODE=True # D√©commentez pour le mode debug de FastAPI/Uvicorn
    ```

4.  **(Optionnel) Installation de l'Ingress Controller NGINX :**
    Si vous souhaitez utiliser un Ingress pour exposer vos services (recommand√© pour une utilisation plus avanc√©e que NodePort) :
    ```bash
    helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
    helm repo update
    helm install nginx-ingress ingress-nginx/ingress-nginx --namespace ingress-nginx --create-namespace
    ```

### Diagrammes de flux

Flux d'authentification actuel :

```mermaid
sequenceDiagram
    participant U as Utilisateur
    participant F as Frontend
    participant A as API d'authentification
    participant S as Session Store
    participant DB as Base de donn√©es

    %% Flux de connexion
    U->>F: Acc√©der √† la page de connexion
    F->>U: Afficher le formulaire de connexion
    U->>F: Soumettre identifiants
    F->>A: POST /api/v1/auth/login
    A->>DB: V√©rifier identifiants
    DB-->>A: Utilisateur valide
    A->>S: Cr√©er une session
    S-->>A: ID de session
    A-->>F: R√©ponse + Cookie de session
    F-->>U: Redirection vers le dashboard

    %% Flux de requ√™te authentifi√©e
    U->>F: Acc√©der √† une page prot√©g√©e
    F->>A: GET /api/v1/... + Cookie de session
    A->>S: V√©rifier la session
    S-->>A: Session valide
    A->>DB: Charger les donn√©es utilisateur
    DB-->>A: Donn√©es utilisateur
    A-->>F: Donn√©es + Autorisation
    F-->>U: Afficher la page prot√©g√©e

    %% Flux de d√©connexion
    U->>F: Cliquer sur d√©connexion
    F->>A: POST /api/v1/auth/logout + Cookie de session
    A->>S: Supprimer la session
    S-->>A: Session supprim√©e
    A-->>F: R√©ponse + Suppression du cookie
    F-->>U: Redirection vers la page de connexion
```

Flux de suppression d'une application (√©tudiant) :

```mermaid
sequenceDiagram
    participant E as √âtudiant
    participant F as Frontend
    participant K as API K8s (FastAPI)
    participant K8s as Kubernetes API

    E->>F: Clic "Supprimer" sur une app
    F->>K: DELETE /api/v1/k8s/deployments/{ns}/{name}?delete_service=true (cookie de session)
    K->>K: V√©rifier session + r√¥le
    alt √âtudiant
        K->>K: Lire le Deployment (ou par stack-name, ou label app)
        K->>K: V√©rifier labels managed-by=labondemand et user-id=√©tudiant
        alt App non poss√©d√©e
            K-->>F: 403 Forbidden
        else App poss√©d√©e
            opt Stack WordPress
                K->>K8s: delete Deployment wordpress et mariadb
                K->>K8s: delete Service(s) associ√©s (si demand√©)
            end
            opt App unitaire
                K->>K8s: delete Deployment {name}
                K->>K8s: delete Service {name}-service (si demand√©)
            end
            K-->>F: 200 OK (message de succ√®s)
            F-->>E: Retirer l‚Äôapp de l‚ÄôUI
        end
    else Admin/Enseignant
        K->>K: Peut supprimer toute app LabOnDemand
        K->>K8s: delete Deployment/Service(s)
        K-->>F: 200 OK
    end
```
### D√©marrage de l'Application

Lancez l'ensemble des services avec Docker Compose :

```bash
docker compose up -d --build
```

Une fois d√©marr√©, l'application sera accessible aux adresses suivantes (par d√©faut) :

*   **Frontend LabOnDemand :** [http://localhost](http://localhost) (ou `http://localhost:${FRONTEND_PORT}`)
*   **API LabOnDemand :** [http://localhost:8000](http://localhost:8000) (ou `http://localhost:${API_PORT}`)

### Terminal int√©gr√© (sans SSH)

Depuis le tableau de bord, ouvrez les d√©tails d‚Äôun d√©ploiement puis lancez le terminal int√©gr√© pour ce pod. Le terminal utilise Xterm.js avec un rendu WebGL (si disponible) et un attachement direct au flux exec du pod (AttachAddon), offrant une latence tr√®s basse et une bonne compatibilit√©. Le redimensionnement est g√©r√© automatiquement.

Restrictions de s√©curit√©:
- Les √©tudiants ne peuvent pas ouvrir un terminal sur les pods de base de donn√©es (labels component=database des stacks mysql/wordpress/lamp).
- Les conteneurs web (ex. LAMP) tournent en non-root, capabilities minimales, seccomp=RuntimeDefault.

Voir la doc: documentation/terminal.md
### Sessions (Redis)

Par d√©faut en d√©veloppement, un service Redis local est d√©marr√© via `compose.yaml` et l'API l'utilise pour stocker les sessions.

- Variable d'environnement principale: `REDIS_URL` (ex: `redis://redis:6379/0`)
- Dur√©e de vie des sessions: `SESSION_EXPIRY_HOURS` (d√©faut: 24h)
- Cookies: `SECURE_COOKIES` (False en dev via Compose; mettez True en prod), `SESSION_SAMESITE`, `COOKIE_DOMAIN`

En production, pointez `REDIS_URL` vers un Redis manag√©/HA.

*   **Documentation API (Swagger UI) :** [http://localhost:8000/docs](http://localhost:8000/docs)
*   **Documentation API (ReDoc) :** [http://localhost:8000/redoc](http://localhost:8000/redoc)

## üìÅ Structure des Fichiers

```
‚îî‚îÄ‚îÄ LabOnDemand /
    ‚îú‚îÄ‚îÄ readme.md           # Ce fichier
    ‚îú‚îÄ‚îÄ compose.yaml        # Configuration Docker Compose
    ‚îú‚îÄ‚îÄ Dockerfile          # Dockerfile pour l'API backend
    ‚îú‚îÄ‚îÄ LICENSE             # Licence du projet
    ‚îú‚îÄ‚îÄ requirements.txt    # D√©pendances Python pour le backend
    ‚îú‚îÄ‚îÄ .env.example        # Mod√®le pour le fichier .env (√Ä CR√âER SI MANQUANT)
    ‚îú‚îÄ‚îÄ backend/
    ‚îÇ   ‚îî‚îÄ‚îÄ main.py         # Logique de l'API FastAPI et interaction Kubernetes
    ‚îú‚îÄ‚îÄ Diagrammes/         # Sch√©mas d'architecture
    ‚îÇ   ‚îú‚îÄ‚îÄ Diagramme-API.drawio
    ‚îÇ   ‚îî‚îÄ‚îÄ diagramme.md
    ‚îú‚îÄ‚îÄ dockerfiles/        # Dockerfiles pour les images des laboratoires
    ‚îÇ   ‚îú‚îÄ‚îÄ jupyter/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
    ‚îÇ   ‚îî‚îÄ‚îÄ vscode/
    ‚îÇ       ‚îî‚îÄ‚îÄ Dockerfile
    ‚îú‚îÄ‚îÄ frontend/           # Fichiers de l'interface utilisateur web
    ‚îÇ   ‚îú‚îÄ‚îÄ index.html
    ‚îÇ   ‚îú‚îÄ‚îÄ script.js
    ‚îÇ   ‚îú‚îÄ‚îÄ style.css
    ‚îÇ   ‚îî‚îÄ‚îÄ css/
    ‚îÇ       ‚îú‚îÄ‚îÄ app-status.css
    ‚îÇ       ‚îî‚îÄ‚îÄ lab-status.css
    ‚îî‚îÄ‚îÄ nginx/
        ‚îî‚îÄ‚îÄ nginx.conf      # Configuration du proxy NGINX
```

## üß© UML (mod√®le conceptuel)

```mermaid
classDiagram
        direction LR
        class User {
            +int id
            +string username
            +UserRole role
        }

        class Session {
            +string session_id
            +datetime created_at
            +int user_id
        }

        class Template {
            +int id
            +string key
            +string name
            +string deployment_type
            +string default_image
            +int default_port
            +string[] tags
            +bool active
        }

        class RuntimeConfig {
            +int id
            +string key
            +string label
            +bool allowed_for_students
            +bool active
        }

        class AppInstance {
            +string name
            +string namespace
            +string app_type
            +map<string,string> labels // managed-by, user-id, stack-name, component
        }

        class QuotaLimits {
            +int max_apps
            +int cpu_m
            +int mem_mi
        }

        class UsageSummary {
            +int apps
            +int cpu_m
            +int mem_mi
            +bool metrics_live
        }

        User "1" -- "*" AppInstance : poss√®de
        Template "1" -- "*" AppInstance : instancie
        User "1" -- "1" QuotaLimits : selon r√¥le
        User "1" -- "1" UsageSummary : consommation
        RuntimeConfig "*" ..> Template : visibilit√©/affichage
```

## üí° D√©veloppement et Maintenance

### Contribution au Projet

Nous encourageons les contributions au projet LabOnDemand ! Voici comment vous pouvez participer :

1. **Fork** le d√©p√¥t GitHub
2. **Cr√©ez une branche** pour votre fonctionnalit√© ou correction
3. **Commitez vos changements** avec des messages clairs
4. **Faites une Pull Request** vers le d√©p√¥t principal

### Ressources et Documentation Suppl√©mentaires

Pour vous aider dans votre utilisation et d√©veloppement avec LabOnDemand, voici quelques ressources additionnelles :

* **[Installation d'un Cluster Kubernetes](https://makhal.fr/posts/k8s/k8s1-3/)** - Guide d√©taill√© pour mettre en place votre propre cluster Kubernetes
* **[Documentation Kubernetes Officielle](https://kubernetes.io/fr/docs/home/)** - R√©f√©rence compl√®te pour l'utilisation de Kubernetes
* **[FastAPI Documentation](https://fastapi.tiangolo.com/)** - Documentation de FastAPI, utilis√© pour le backend de l'application
* **Docs du projet**
    * `documentation/QUICKSTART.md` ‚Äî D√©marrage rapide (Docker Compose, kubeconfig)
    * `documentation/auth-flow.md` ‚Äî D√©tails d‚Äôauthentification et s√©curit√© des sessions
    * `documentation/wordpress.md` ‚Äî Stack WordPress (web + mariadb), notes de suppression
    * `documentation/auth-summary.md` ‚Äî R√©sum√© des r√¥les et autorisations
    * `documentation/pvc-mise-en-place.md` ‚Äî Stockage persistant

## üìù Licence

Ce projet est sous licence [GNU AFFERO GENERAL PUBLIC LICENSE v3](LICENSE) - voir le fichier LICENSE pour plus de d√©tails.

---

¬© 2025 LabOnDemand - Cr√©√© avec ‚ù§Ô∏è par Mohamad El Akhal.